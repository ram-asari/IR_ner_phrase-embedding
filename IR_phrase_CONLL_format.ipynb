{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR_phrase_CONLL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZyzX0SHrXc4"
      },
      "source": [
        "import csv\n",
        "import re\n",
        "import pandas as pd\n",
        "import string"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjFtnJ2-rcOG"
      },
      "source": [
        "data = []\n",
        "temp_data = []\n",
        "noun_phrase = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z6HU2Zme5l3",
        "outputId": "8c883b99-b129-42c6-df54-628dd3263337"
      },
      "source": [
        "!git clone https://ram-asari:akshith.a%401@github.com/ram-asari/IR_ner_phrase-embedding.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IR_ner_phrase-embedding'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 44 (delta 19), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHNtC8I9SwYd"
      },
      "source": [
        "df1 = pd.read_excel('/content/NER_TWEET_DATA(1).xlsx', sheet_name = 'Rajeev', header=None)\n",
        "df2 = pd.read_excel('/content/NER_TWEET_DATA(1).xlsx', sheet_name = 'Ramji', header=None)\n",
        "df3 = pd.read_excel('/content/NER_TWEET_DATA(1).xlsx', sheet_name = 'Ratnesh', header=None)\n",
        "df4 = pd.read_excel('/content/NER_TWEET_DATA(1).xlsx', sheet_name = 'Ramprasad', header=None)\n",
        "df5 = pd.read_excel('/content/NER_TWEET_DATA(1).xlsx', sheet_name = 'Pragati', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hy6eOGefMvU"
      },
      "source": [
        "df = pd.read_csv('/content/IR_ner_phrase-embedding/NER_tweet_data.csv', header= None)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkLB1mu9UKYc"
      },
      "source": [
        "# df = df1.append(df2)\n",
        "# df = df.append(df3)\n",
        "# df = df.append(df4)\n",
        "# df = df.append(df5)\n",
        "df = df.sample(frac = 1) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "lY9NDAJzmg-l",
        "outputId": "eebf158e-2859-4cd6-9041-8ad5e5d71cba"
      },
      "source": [
        "df = df.sample(frac = 1) \n",
        "df = df[[1,2,3]]\n",
        "df.dropna(inplace=True)\n",
        "df"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>Masterstroke to Modiji ne usi din maar diya th...</td>\n",
              "      <td>Modiji</td>\n",
              "      <td>maar diya tha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>\"Jab ye iski biwi, bahu beti ke sath hoga tab ...</td>\n",
              "      <td>biwi, bahu,beti</td>\n",
              "      <td>tab pata chalega</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>So stupid &amp; idiotic that @narendramodi ke #mod...</td>\n",
              "      <td>narendramodi:BanarasHinduUniversity:VcofficeBHU</td>\n",
              "      <td>stupid &amp; idiotic: kuch bhi chutiyaape: present...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>@TarekFatah saab Mubarak ho! Aap ke efforts ab...</td>\n",
              "      <td>TarekFatah</td>\n",
              "      <td>rang dikhane lage hain :</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>655</th>\n",
              "      <td>@narendramodi @PMOIndia @arunjaitley ye #GST k...</td>\n",
              "      <td>narendramodi:arunjaitley:india:PMOIndia:GST</td>\n",
              "      <td>mehnga bill:bana k de rahe:aap sab kahan:mar g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>@INCIndia Yeh frustration tum logo k chehre pr...</td>\n",
              "      <td>INCIndia:ZakirNaik:Aiyyar:China:Aadhar:GST:NIA...</td>\n",
              "      <td>frustration tum logo: chehre pr mujhe: ghaav t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>\"@KapilSibal what a shame such bheja less, nal...</td>\n",
              "      <td>KapilSibal:desh</td>\n",
              "      <td>hona hi thaa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>645</th>\n",
              "      <td>Kya din aa gaye hai ghatiya WhatsApp jokes twe...</td>\n",
              "      <td>WhatsApp:GST:devanagari</td>\n",
              "      <td>Kya din aa gaye hai:pad raha hai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>1 saal pehle aapk bahut videos dekha jisme aap...</td>\n",
              "      <td>modi:GST</td>\n",
              "      <td>ki tarif karte the :  kar k thakk gaye : ka hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>\"kahan gaye wo log jo \"\"10 things to know blah...</td>\n",
              "      <td>GST</td>\n",
              "      <td>kahan gaye wo log:kuchh leekho saalon</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>895 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     1  ...                                                  3\n",
              "76   Masterstroke to Modiji ne usi din maar diya th...  ...                                      maar diya tha\n",
              "268  \"Jab ye iski biwi, bahu beti ke sath hoga tab ...  ...                                   tab pata chalega\n",
              "380  So stupid & idiotic that @narendramodi ke #mod...  ...  stupid & idiotic: kuch bhi chutiyaape: present...\n",
              "215  @TarekFatah saab Mubarak ho! Aap ke efforts ab...  ...                          rang dikhane lage hain : \n",
              "655  @narendramodi @PMOIndia @arunjaitley ye #GST k...  ...  mehnga bill:bana k de rahe:aap sab kahan:mar g...\n",
              "..                                                 ...  ...                                                ...\n",
              "378  @INCIndia Yeh frustration tum logo k chehre pr...  ...  frustration tum logo: chehre pr mujhe: ghaav t...\n",
              "308  \"@KapilSibal what a shame such bheja less, nal...  ...                                       hona hi thaa\n",
              "645  Kya din aa gaye hai ghatiya WhatsApp jokes twe...  ...                   Kya din aa gaye hai:pad raha hai\n",
              "594  1 saal pehle aapk bahut videos dekha jisme aap...  ...  ki tarif karte the :  kar k thakk gaye : ka hi...\n",
              "631  \"kahan gaye wo log jo \"\"10 things to know blah...  ...              kahan gaye wo log:kuchh leekho saalon\n",
              "\n",
              "[895 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yETTfcDsuK0l"
      },
      "source": [
        "df = df[df[2] != 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37LHxUdsohmN"
      },
      "source": [
        "df_list = df.values.tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WShsKiA8o0n9",
        "outputId": "9237d108-9cdc-4f65-8b44-8c48eaa7ff36"
      },
      "source": [
        "df_list[5][2].split(':')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abhi_haal hi_m', ' fake rajput']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Gzh1Y60B9D"
      },
      "source": [
        "train_data  = df_list[:627] \n",
        "val_data = df_list[627:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCFutBK-DmnU"
      },
      "source": [
        "# Phrases dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwNBK-oCvkt6"
      },
      "source": [
        "punk = string.punctuation.replace('-', '').replace('_', '')\n",
        "punk = punk+'â€¦'\n",
        "phrase_dict = {}\n",
        "ph_count = 0\n",
        "\n",
        "for line in df_list:\n",
        "\n",
        "  for phrase in line[2].split(':'):\n",
        "    table = phrase.maketrans(punk, ' '*len(punk))\n",
        "    cleaned = phrase.translate(table)\n",
        "    cleaned = re.sub(r\"\\s+\",\" \",cleaned)\n",
        "    cleaned = cleaned.strip()\n",
        "    cleaned = cleaned.lower()\n",
        "    if len(cleaned) > 1:\n",
        "      if phrase_dict.get(cleaned, -1) == -1:\n",
        "        phrase_dict[cleaned] = 1\n",
        "      else:\n",
        "        phrase_dict[cleaned] += 1\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5krtj0H6EtES"
      },
      "source": [
        "phrase_count = 0 \n",
        "for ph, count in phrase_dict.items():\n",
        "  if count > 5 :\n",
        "    print(ph)\n",
        "    phrase_count += 1\n",
        "print(phrase_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm0BnNhVDqUR"
      },
      "source": [
        "# CONLL formatting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8INV_zQB0d7S"
      },
      "source": [
        "tot_data = [train_data, val_data]\n",
        "punk = string.punctuation.replace('-', '').replace('_', '')\n",
        "punk = punk+'â€¦'\n",
        "\n",
        "# for iiii, gen_data in enumerate(tot_data):\n",
        "#   data = []\n",
        "with open('/content/ner_conll.txt','w') as write_txt:\n",
        "  for idx, line in enumerate(df_list):\n",
        "    cleaned_line = []\n",
        "    cleaned = line[0]\n",
        "    if cleaned.find('http') != -1:\n",
        "      end_idx = 0\n",
        "      for i in range(cleaned.find('http'), len(cleaned)):\n",
        "        end_idx = i\n",
        "        if cleaned[i] == ' ':\n",
        "          cleaned = cleaned[:cleaned.find('http')]+ cleaned[i:]\n",
        "          break\n",
        "      if end_idx == len(cleaned):\n",
        "        cleaned = cleaned[:cleaned.find('http')]\n",
        "\n",
        "    table = cleaned.maketrans(punk, ' '*len(punk))\n",
        "    cleaned = cleaned.translate(table)\n",
        "    cleaned = re.sub(r\"\\s+\",\" \",cleaned)\n",
        "    cleaned = cleaned.strip()\n",
        "    cleaned = cleaned.lower()\n",
        "    data.append(cleaned)\n",
        "    cleaned_line.append(cleaned)\n",
        "\n",
        "\n",
        "    table = line[1].maketrans(punk, ' '*len(punk))\n",
        "    cleaned = line[1].translate(table)\n",
        "    cleaned = re.sub(r\"\\s+\",\" \",cleaned)\n",
        "    cleaned = cleaned.lower()\n",
        "    cleaned_line.append(cleaned)\n",
        "\n",
        "    table = line[2].maketrans(punk, ' '*len(punk))\n",
        "    cleaned = line[2].translate(table)\n",
        "    cleaned = re.sub(r\"\\s+\",\" \",cleaned)\n",
        "    cleaned = cleaned.lower()\n",
        "    cleaned_line.append(cleaned)\n",
        "\n",
        "    #this is for phrase replacing\n",
        "    ##############################################\n",
        "    for i_id, phrase  in enumerate(phrase_dict.items()):\n",
        "      # print(phrase[0], i_id)\n",
        "      cleaned_line[0] = cleaned_line[0].replace(phrase[0], 's*s*r^'+str(i_id)) \n",
        "      # print(cleaned_line[0])\n",
        "    ############################################\n",
        "\n",
        "    write_txt.write(\"'''\")\n",
        "    write_txt.write('\\n')\n",
        "\n",
        "    for word in cleaned_line[0].lower().split():\n",
        "      nouns = list(cleaned_line[1].lower().split())\n",
        "      if word in nouns:\n",
        "        # data.append(str(idx)+' '+word+' '+'N')\n",
        "        write_txt.write(str(idx)+' '+word+' '+'N')\n",
        "        write_txt.write('\\n')\n",
        "      else:\n",
        "        # data.append(str(idx)+' '+word+' '+'OTH')\n",
        "        write_txt.write(str(idx)+' '+word+' '+'OTH')\n",
        "        write_txt.write('\\n')\n",
        "\n",
        "    write_txt.write(\"'''\")\n",
        "    idx += 1\n",
        "    write_txt.write('\\n')\n",
        "    write_txt.write('\\n')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}